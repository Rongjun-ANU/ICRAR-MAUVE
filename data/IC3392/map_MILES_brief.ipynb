{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed62f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib import request\n",
    "from scipy.interpolate import interp1d\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import speclite.filters as sp\n",
    "from speclite import filters\n",
    "from scipy.ndimage import sum_labels, mean\n",
    "\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "from astropy import constants as c\n",
    "from astropy.wcs import WCS\n",
    "from astropy.wcs.utils import proj_plane_pixel_scales\n",
    "\n",
    "from ppxf.ppxf import ppxf, rebin\n",
    "import ppxf.ppxf_util as util\n",
    "from ppxf import sps_util as lib\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03cb2b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /Users/Igniz/Desktop/ICRAR/data/IC3392/IC3392_SPATIAL_BINNING_maps.fits\n",
      "Filename: IC3392_SPATIAL_BINNING_maps.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       4   ()      \n",
      "  1  BINID         1 ImageHDU        26   (437, 438)   float64   \n",
      "  2  FLUX          1 ImageHDU        26   (437, 438)   float64   \n",
      "  3  SNR           1 ImageHDU        26   (437, 438)   float64   \n",
      "  4  SNRBIN        1 ImageHDU        26   (437, 438)   float64   \n",
      "  5  XBIN          1 ImageHDU        26   (437, 438)   float64   \n",
      "  6  YBIN          1 ImageHDU        26   (437, 438)   float64   \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load spatial binning map IC3392_individual.fits \n",
    "# --------- file location (edit if needed) ----------\n",
    "binning_path = Path(\"IC3392_SPATIAL_BINNING_maps.fits\")\n",
    "print(\"Loading:\", binning_path.resolve())\n",
    "with fits.open(binning_path) as hdul:\n",
    "    # check data structure and header\n",
    "    print(hdul.info())\n",
    "    binning_primary = hdul[0]\n",
    "    binning_BINID   = hdul[1].data\n",
    "    binning_FLUX    = hdul[2].data\n",
    "    binning_hdr     = hdul[1].header\n",
    "    hdul.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11719bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /Users/Igniz/Desktop/ICRAR/data/IC3392/IC3392_sfh-weights.fits\n",
      "Filename: IC3392_sfh-weights.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU      23   ()      \n",
      "  1  WEIGHTS       1 BinTableHDU     27   4077R x 1C   [477D]   \n",
      "  2  GRID          1 BinTableHDU     31   477R x 3C   [D, D, D]   \n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load SFH and weights data IC3392_sfh-weights.fits\n",
    "# --------- file location (edit if needed) ----------\n",
    "sfh_path = Path(\"IC3392_sfh-weights.fits\")\n",
    "print(\"Loading:\", sfh_path.resolve())\n",
    "with fits.open(sfh_path) as hdul:\n",
    "    # check data structure and header\n",
    "    print(hdul.info())\n",
    "    weights_data = hdul[1].data\n",
    "    grid_data = hdul[2].data\n",
    "    weights_hdr  = hdul[1].header\n",
    "    grid_hdr  = hdul[2].header\n",
    "\n",
    "    hdul.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "884f993f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 636 out of 636 rows of data from BaSTI+Chabrier.dat\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- 2.1  Column names (from HEADER_out_phot) ----------\n",
    "names = [\n",
    "    'IMF','slope','MH','Age','U','B','V','R','I','J','H','K',\n",
    "    'UminusV','BminusV','VminusR','VminusI','VminusJ','VminusH','VminusK',\n",
    "    'ML_U','ML_B','ML_V','ML_R','ML_I','ML_J','ML_H','ML_K',\n",
    "    'F439W','F555W','F675W','F814W','C439_555','C555_675','C555_814'\n",
    "]\n",
    "\n",
    "fname = Path(\"BaSTI+Chabrier.dat\")\n",
    "\n",
    "# ---------- 2.2  Load data, skip the two header lines ----------\n",
    "tbl = np.genfromtxt(\n",
    "    fname, dtype=None, encoding=None, names=names,\n",
    "    comments='#', skip_header=2, autostrip=True\n",
    ")                                  # :contentReference[oaicite:2]{index=2}\n",
    "\n",
    "# ---------- 2.3  Keep only Chabrier rows ----------\n",
    "mask = (tbl['IMF'] == 'Ch')\n",
    "phot = tbl[mask]\n",
    "\n",
    "print(f\"Loaded {len(phot)} out of {len(tbl)} rows of data from {fname.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09048d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3.1  Build a lookup dict keyed by (logAge, MH) rounded to 2 dec —--\n",
    "key_ml = {}\n",
    "\n",
    "for row in phot:\n",
    "    age_gyr = round(row['Age'], 2)                     # e.g. 0.03 → 0.03\n",
    "    mh_dex  = round(row['MH'],  2)                     # e.g. –2.27 → –2.27\n",
    "    mlr     = row['ML_R']                   # keep 2 dp as requested\n",
    "    key_ml[(age_gyr, mh_dex)] = mlr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "900813ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid = grid_data  # the FITS_rec you already loaded\n",
    "\n",
    "# --- 4.1  Prepare new array with an extra ML_R column -------------\n",
    "mlr_values = np.full(len(grid), np.nan, dtype=np.float32)\n",
    "\n",
    "for i, (logage, mh, _) in enumerate(grid):\n",
    "    age_gyr = round(10**logage, 2)   # yrs → Gyr, 2 dp\n",
    "    mh_dex  = round(mh, 2)                 # already dex\n",
    "    mlr_values[i] = key_ml.get((age_gyr, mh_dex), np.nan)\n",
    "\n",
    "# --- 4.2  Build a new structured array including ML_R -------------\n",
    "ml_dtype = grid.dtype.descr + [('ML_R', 'f4')]\n",
    "grid_mlr  = np.empty(len(grid), dtype=ml_dtype)\n",
    "\n",
    "for name in grid.dtype.names:\n",
    "    grid_mlr[name] = grid[name]\n",
    "grid_mlr['ML_R'] = mlr_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "516c0af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- prerequisites already in memory ---------------------------------------\n",
    "# weights_data['WEIGHTS']   -> (4077, 477)   light fractions per bin\n",
    "# grid_mlr['ML_R']          -> (477,)        R-band M/L per template\n",
    "\n",
    "# 1) convert the opaque FITS_rec into a plain ndarray\n",
    "w      = weights_data['WEIGHTS'].astype(np.float32)        # (4077, 477)\n",
    "ml_ssp = grid_mlr['ML_R'].astype(np.float32)               # (477,)\n",
    "\n",
    "# 2) light-weighted M/L_R per Voronoi bin (shape 4077)\n",
    "ml_bin = (w * ml_ssp).sum(axis=1)     # or: np.dot(w, ml_ssp)\n",
    "\n",
    "# 3) optional sanity check: every bin should return a finite, positive value\n",
    "assert np.all(np.isfinite(ml_bin)) and (ml_bin > 0).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73fef940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0)  inputs already in memory ------------------------------------------\n",
    "# binning_BINID  -> (ny, nx) float array   (NaN   = originally masked pixel\n",
    "#                                            <0    = masked, but *belongs to* |id|)\n",
    "# ml_bin         -> (N_bin,) float array   (your 4 077 zone M/L_R values)\n",
    "\n",
    "# --- 1)  create blank map, same shape & dtype ------------------------------\n",
    "binning_MLR = np.full_like(binning_BINID, np.nan, dtype=np.float32)\n",
    "\n",
    "# --- 2)  fill *valid* Voronoi zones ----------------------------------------\n",
    "valid = binning_BINID >= 0                     # True where BINID is a real zone\n",
    "binning_MLR[valid] = ml_bin[binning_BINID[valid].astype(int)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea579711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing AB magnitudes for each spaxel...\n",
      "Processing row 0/438\n",
      "Processing row 50/438\n",
      "Processing row 100/438\n",
      "Processing row 150/438\n",
      "Processing row 200/438\n",
      "Processing row 250/438\n",
      "Processing row 300/438\n",
      "Processing row 350/438\n",
      "Processing row 400/438\n",
      "R-band magnitude calculation completed!\n",
      "Filter used: bessell-R\n",
      "Magnitude range: 21.12 to 26.07\n",
      "Distance modulus: 31.09 mag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/clp89v210v32vh5vjt2kx7b80000gr/T/ipykernel_14126/1492270148.py:57: RuntimeWarning: invalid value encountered in cast\n",
      "  BINID   = BINID_f32.astype(np.int32)   # safe: all finite →\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 0.  File paths\n",
    "# ---------------------------------------------------------------------\n",
    "cube_path = Path(\"IC3392_DATACUBE_FINAL_WCS_Pall_mad_red_v3.fits\")\n",
    "vor_path  = Path(\"IC3392_SPATIAL_BINNING_maps.fits\")\n",
    "sfh_path  = Path(\"IC3392_SFH_maps.fits\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1.  R-band magnitude map per spaxel using speclite\n",
    "# ---------------------------------------------------------------------\n",
    "cube = fits.open(cube_path, memmap=False)\n",
    "data = cube[\"DATA\"].data.astype(np.float32)          # (nz, ny, nx)\n",
    "hdr  = cube[\"DATA\"].header\n",
    "nz, ny, nx = data.shape\n",
    "\n",
    "# wavelength grid (native header unit → Å)\n",
    "spec_wcs   = WCS(hdr).sub([\"spectral\"])              # 1-axis WCS\n",
    "wave_native = spec_wcs.all_pix2world(\n",
    "                 np.arange(nz)[:, None], 0)[:, 0]    # numeric values\n",
    "wave = (wave_native * spec_wcs.wcs.cunit[0]).to(u.AA)   # use cunit[0]\n",
    "\n",
    "# Load filter using speclite (more robust than synphot for this purpose)\n",
    "f_r = filters.load_filter('bessell-R')  \n",
    "# decamDR1noatm-r, bessell-R or 'sdss2010noatm-r'/'sdss2010-r' for SDSS r-band\n",
    "\n",
    "# Convert flux units: MUSE cube is in 1e-20 erg s⁻¹ cm⁻² Å⁻¹\n",
    "F_lambda = data * (1e-20 * u.erg / (u.s * u.cm**2 * u.AA))  # Add units \n",
    "\n",
    "# Calculate AB magnitude for each spaxel\n",
    "ny, nx = data.shape[1], data.shape[2]\n",
    "m_r_map = np.full((ny, nx), np.nan, dtype=np.float32)\n",
    "maggies = np.full((ny, nx), np.nan, dtype=np.float32)\n",
    "\n",
    "print(\"Computing AB magnitudes for each spaxel...\")\n",
    "for j in range(ny):\n",
    "    if j % 50 == 0:  # Progress indicator\n",
    "        print(f\"Processing row {j}/{ny}\")\n",
    "    for i in range(nx):\n",
    "        # Extract spectrum for this spaxel\n",
    "        spectrum = F_lambda[:, j, i]\n",
    "        m_r_map[j, i] = f_r.get_ab_magnitude(spectrum, wavelength=wave)\n",
    "        maggies[j, i] = f_r.get_ab_maggies(spectrum, wavelength=wave)\n",
    "cube.close()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2.  Collapse to Voronoi bins\n",
    "# ---------------------------------------------------------------------\n",
    "with fits.open(vor_path) as hd_v:\n",
    "    # ---------- PATCH BEGIN ----------\n",
    "    # keep BINID as float so NaNs survive the read\n",
    "    BINID_f32 = hd_v[\"BINID\"].data.astype(np.float32)\n",
    "    muse_hdr2 = hd_v[\"BINID\"].header\n",
    "    nan_mask  = ~np.isfinite(hd_v[\"FLUX\"].data)\n",
    "\n",
    "    # build an *integer* copy with sentinel -1 for “no bin”\n",
    "    bad_pix = (~np.isfinite(BINID_f32)) | (BINID_f32 < 0)\n",
    "    BINID   = BINID_f32.astype(np.int32)   # safe: all finite →\n",
    "    BINID[bad_pix] = -1                   # mark blanks with −1\n",
    "    # ---------- PATCH END ----------\n",
    "\n",
    "uniq = np.unique(BINID[BINID >= 0])                 # keep this line\n",
    "\n",
    "# Convert magnitude map to flux for averaging\n",
    "F0_ref = 3631e-23  # Reference flux in erg s⁻¹ cm⁻² Hz⁻¹ for AB magnitude zero point\n",
    "flux_map = F0_ref * 10**(-0.4 * m_r_map)  # Convert mag to flux\n",
    "flux_map[nan_mask] = np.nan  # Keep NaNs where needed\n",
    "\n",
    "# Average flux in each bin (excluding NaN pixels)\n",
    "flux_map_clean = np.where(nan_mask | ~np.isfinite(m_r_map), np.nan, flux_map)\n",
    "valid_pixels = sum_labels(~np.isnan(flux_map_clean), BINID, uniq)\n",
    "sum_flux = sum_labels(np.nan_to_num(flux_map_clean), BINID, uniq)\n",
    "mean_flux = np.divide(sum_flux, valid_pixels, \n",
    "                     out=np.full_like(sum_flux, np.nan), \n",
    "                     where=valid_pixels > 0)\n",
    "\n",
    "# Convert back to magnitudes\n",
    "mean_mag = -2.5 * np.log10(mean_flux / F0_ref)\n",
    "\n",
    "# Create lookup table for bin-averaged magnitudes\n",
    "lut = np.full(int(BINID.max()) + 1, np.nan, dtype=np.float32)\n",
    "lut[uniq] = mean_mag\n",
    "m_r_binned = lut[BINID]                                    # (ny, nx)\n",
    "m_r_binned[nan_mask] = np.nan  # Keep NaNs where needed\n",
    "flux_map_binned = F0_ref * 10**(-0.4 * m_r_binned)  # Convert mag to flux\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3.  Galactic-extinction correction\n",
    "# ---------------------------------------------------------------------\n",
    "EBV = fits.getdata(sfh_path, \"EBV\").astype(np.float32)\n",
    "\n",
    "# Choose extinction coefficient based on your filter choice:\n",
    "if 'bessell' in f_r.name.lower():\n",
    "    A_r = 2.32 * EBV  # Bessell R-band coefficient (Fitzpatrick 1999)\n",
    "    M_r_sun = 4.64    # Solar absolute magnitude in Bessell R\n",
    "elif 'sdss' in f_r.name.lower():\n",
    "    A_r = 2.285 * EBV  # SDSS r-band coefficient (Schlafly & Finkbeiner 2011)\n",
    "    M_r_sun = 4.64     # Solar absolute magnitude in SDSS r\n",
    "else:\n",
    "    print(f\"Warning: Unknown filter {f_r.name}, using SDSS coefficients\")\n",
    "    A_r = 2.285 * EBV\n",
    "    M_r_sun = 4.64\n",
    "\n",
    "# Apply extinction correction to magnitudes (subtract extinction)\n",
    "m_r_corr = m_r_binned - A_r  # Magnitude correction\n",
    "m_r_corr[nan_mask] = np.nan\n",
    "\n",
    "# magnitude back to nanomaggies in Legacy survey format\n",
    "def magnitude_to_nanomaggies(magnitude):\n",
    "    return 10**((22.5 - magnitude) / 2.5)\n",
    "FLUX_R_corr = magnitude_to_nanomaggies(m_r_corr)  # Convert to flux\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4.  Luminosity → stellar-mass map\n",
    "# ---------------------------------------------------------------------\n",
    "# Distance modulus for 16.5 Mpc\n",
    "distmod = 5 * np.log10((16.5 * u.Mpc).to(u.pc).value / 10)\n",
    "\n",
    "# Absolute magnitude\n",
    "M_r = m_r_corr - distmod\n",
    "\n",
    "# Luminosity in solar units\n",
    "L_Lsun = 10**(-0.4 * (M_r - M_r_sun))\n",
    "\n",
    "# Stellar mass (uncomment when binning_MLR is available)\n",
    "M_star = L_Lsun * binning_MLR\n",
    "logM_star = np.where(M_star > 0, np.log10(M_star), np.nan)\n",
    "logM_star[nan_mask] = np.nan\n",
    "\n",
    "print(\"R-band magnitude calculation completed!\")\n",
    "print(f\"Filter used: {f_r.name}\")\n",
    "print(f\"Magnitude range: {np.nanmin(m_r_corr):.2f} to {np.nanmax(m_r_corr):.2f}\")\n",
    "print(f\"Distance modulus: {distmod:.2f} mag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05c45129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved extended file to /Users/Igniz/Desktop/ICRAR/data/IC3392/IC3392_SPATIAL_BINNING_maps_extended.fits\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# inputs already in memory:\n",
    "#   binning_MLR  -> (438, 437) float32   (we’ll cast to float64 like others)\n",
    "#   binning_path -> Path to original file (\"IC3392_SPATIAL_BINNING_maps.fits\")\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "out_path = Path(\"IC3392_SPATIAL_BINNING_maps_extended.fits\")\n",
    "\n",
    "# 1) read the whole HDUList from disk\n",
    "with fits.open(binning_path) as hdul:\n",
    "    # 2) clone all existing HDUs into a new list\n",
    "    new_hdul = fits.HDUList([hdu.copy() for hdu in hdul])\n",
    "\n",
    "# 3) build the new FLUX_R_corr image HDU\n",
    "FLUX_R_corr_hdu = fits.ImageHDU(\n",
    "    data=FLUX_R_corr.astype(np.float64), name=\"FLUX_R_corr\")\n",
    "\n",
    "# 4) keep WCS and pixel-scale info by copying the original BINID header\n",
    "FLUX_R_corr_hdu.header.update(binning_hdr)         # you created binning_hdr earlier\n",
    "FLUX_R_corr_hdu.header[\"EXTNAME\"] = \"FLUX_R_corr\"\n",
    "FLUX_R_corr_hdu.header[\"BUNIT\"]   = \"erg/s/cm2/Hz\"  # physical units\n",
    "\n",
    "# 5) append and write to disk\n",
    "new_hdul.append(FLUX_R_corr_hdu)\n",
    "new_hdul.writeto(out_path, overwrite=True)\n",
    "\n",
    "print(f\"Saved extended file to {out_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "855a2944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M/L_R layer saved ➜ /Users/Igniz/Desktop/ICRAR/data/IC3392/IC3392_SPATIAL_BINNING_maps_extended.fits\n"
     ]
    }
   ],
   "source": [
    "with fits.open(out_path, mode=\"append\") as hdul:             # open existing file\n",
    "    new_hdu = fits.ImageHDU(data=binning_MLR.astype(np.float64),  # like others\n",
    "                             header=binning_hdr, name=\"ML_R\")\n",
    "    new_hdu.header[\"EXTNAME\"] = \"ML_R\"                       # name keyword\n",
    "    new_hdu.header[\"BUNIT\"] = \"Msol/Lsol_R\"                   # units keyword\n",
    "    hdul.append(new_hdu)                                    # add as 9-th HDU\n",
    "    hdul.flush()                                             # write in-place\n",
    "\n",
    "print(\"M/L_R layer saved ➜\", out_path.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f18de3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stellar-mass layer saved ➜ /Users/Igniz/Desktop/ICRAR/data/IC3392/IC3392_SPATIAL_BINNING_maps_extended.fits\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# INPUTS already in memory\n",
    "#   logM_star      (438, 437)  float32   ← log10(M*/M☉) per spaxel\n",
    "#   binning_hdr    WCS header you copied from the BINID image\n",
    "#   out_path       Path(\"IC3392_SPATIAL_BINNING_maps_extended.fits\")\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "with fits.open(out_path, mode=\"append\") as hdul:             # open existing file\n",
    "    mass_hdu = fits.ImageHDU(data=logM_star.astype(np.float64),  # like others\n",
    "                             header=binning_hdr, name=\"LOGMSTAR\")\n",
    "    mass_hdu.header[\"BUNIT\"] = \"log(Msol)\"                   # units keyword\n",
    "    hdul.append(mass_hdu)                                    # add as 9-th HDU\n",
    "    hdul.flush()                                             # write in-place\n",
    "\n",
    "print(\"Stellar-mass layer saved ➜\", out_path.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "327b8341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the stellar mass surface density \n",
    "# Convert to surface density in M☉/pc²\n",
    "# 1. Convert pixel area to physical area in pc²\n",
    "legacy_wcs2 = WCS(binning_hdr).celestial  # strip spectral axis\n",
    "pixel_scale = (proj_plane_pixel_scales(legacy_wcs2) * u.deg).to(u.arcsec)\n",
    "pixel_area_Mpc = ((pixel_scale[0]).to(u.rad).value*16.5*u.Mpc)*(((pixel_scale[1]).to(u.rad).value*16.5*u.Mpc))\n",
    "pixel_area_kpc = pixel_area_Mpc.to(u.kpc**2)\n",
    "# 2. Convert stellar mass to surface density\n",
    "stellar_mass_surface_density = M_star / pixel_area_kpc  # M☉/kpc²\n",
    "# 3. Convert to log10 scale\n",
    "log_stellar_mass_surface_density = np.log10(stellar_mass_surface_density.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5ca171c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stellar mass surface density layer saved ➜ /Users/Igniz/Desktop/ICRAR/data/IC3392/IC3392_SPATIAL_BINNING_maps_extended.fits\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# INPUTS already in memory\n",
    "#   logM_star      (438, 437)  float32   ← log10(M*/M☉) per spaxel\n",
    "#   binning_hdr    WCS header you copied from the BINID image\n",
    "#   out_path       Path(\"IC3392_SPATIAL_BINNING_maps_extended.fits\")\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "with fits.open(out_path, mode=\"append\") as hdul:             # open existing file\n",
    "    mass_density_hdu = fits.ImageHDU(\n",
    "        data=log_stellar_mass_surface_density.astype(np.float64),  # like others\n",
    "        header=binning_hdr, name=\"LOGMASS_SURFACE_DENSITY\")\n",
    "    mass_density_hdu.header[\"BUNIT\"] = \"log(Msol/kpc2)\"  # units keyword\n",
    "    hdul.append(mass_density_hdu)                                    # add as 10-th HDU \n",
    "    hdul.flush()                                             # write in-place\n",
    "print(\"Stellar mass surface density layer saved ➜\", out_path.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed855098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-band magnitude layer saved ➜ /Users/Igniz/Desktop/ICRAR/data/IC3392/IC3392_SPATIAL_BINNING_maps_extended.fits\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# INPUTS already in memory\n",
    "#   m_R            (438, 437)  float32   ← log10(M*/M☉) per spaxel\n",
    "#   binning_hdr    WCS header you copied from the BINID image\n",
    "#   out_path       Path(\"IC3392_SPATIAL_BINNING_maps_extended.fits\")\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "with fits.open(out_path, mode=\"append\") as hdul:             # open existing file\n",
    "    m_r_hdu = fits.ImageHDU(data=m_r_corr.astype(np.float64),  # like others\n",
    "                             header=binning_hdr, name=\"magnitude_r\")\n",
    "    m_r_hdu.header[\"BUNIT\"] = \"mag_AB\"                   # units keyword\n",
    "    hdul.append(m_r_hdu)                                    # add as 9-th HDU\n",
    "    hdul.flush()                                             # write in-place\n",
    "\n",
    "print(\"r-band magnitude layer saved ➜\", out_path.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "167b43c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# INPUTS already in memory\n",
    "#   m_R            (438, 437)  float32   ← log10(M*/M☉) per spaxel\n",
    "#   binning_hdr    WCS header you copied from the BINID image\n",
    "#   out_path       Path(\"IC3392_SPATIAL_BINNING_maps_extended.fits\")\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "with fits.open(out_path, mode=\"append\") as hdul:             # open existing file\n",
    "    m_r_uncorrected_hdu = fits.ImageHDU(data=m_r_binned.astype(np.float64),  # like others\n",
    "                             header=binning_hdr, name=\"magnitude_r_uncorrected\")\n",
    "    m_r_uncorrected_hdu.header[\"BUNIT\"] = \"mag_AB\"                   # units keyword\n",
    "    hdul.append(m_r_uncorrected_hdu)                                    # add as 9-th HDU\n",
    "    hdul.flush()                                             # write in-place\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02529384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ICRAR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
